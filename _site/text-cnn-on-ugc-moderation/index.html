<!DOCTYPE html> <!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]--> <!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]--> <!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]--> <!--[if gt IE 8]><!--> <html class="no-js"><!--<![endif]--> <head> <meta charset="UTF-8"> <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> <meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"> <title>TextCNN on UGC (user generated content) moderation &#8211; Marsan Ma's info</title> <meta name="description" content="Marsan Ma's info"> <meta name="keywords" content="nlp, deep learning, neural network, cnn"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:image" content="http://localhost:4000//assets/img/blog/textcnn.png"> <meta name="twitter:title" content="TextCNN on UGC (user generated content) moderation"> <meta name="twitter:description" content="TextCNN is my new standard for quick-and-dirty fast NLP model building, it’s fast and simple, natively include feature engineering as model and trained together."> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="TextCNN on UGC (user generated content) moderation"> <meta property="og:description" content="TextCNN is my new standard for quick-and-dirty fast NLP model building, it’s fast and simple, natively include feature engineering as model and trained together."> <meta property="og:url" content="http://localhost:4000/text-cnn-on-ugc-moderation/"> <meta property="og:site_name" content="Marsan Ma's info"> <meta property="og:image" content="http://localhost:4000/assets/img/logo.png"> <link rel="canonical" href="http://localhost:4000/text-cnn-on-ugc-moderation/"> <link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Marsan Ma's info Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css"> <!-- JS --> <script src="http://localhost:4000/assets/js/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" href="http://localhost:4000/assets/img/favicons/apple-icon-precomposed.png"> <link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="http://localhost:4000/favicon.png" /> <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" /> <!-- Background Image --> <style type="text/css">body {background-image:url(http://localhost:4000/assets/img/placeholder-big.jpg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> <style type="text/css">.feature {background-image:url(http://localhost:4000//assets/img/blog/textcnn.png);}</style> </head> <body> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="http://localhost:4000/">Home</a></li> <li> <a href="#">About</a> <ul class="dl-submenu"> <li> <img src="http://localhost:4000/assets/img/logo.png" alt="Marsan Ma's info photo" class="author-photo"> <h4>Marsan Ma's info</h4> <p>Marsan Ma's info</p> </li> <li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="http://linkedin.com/in/marsanma" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a> </li> <li> <a href="http://github.com/Marsan-Ma" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> <li> <a href="mailto:marsan@gmail.com" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-envelope-square"></i> Email</a> </li> </ul><!-- /.dl-submenu --> </li> <li> <a href="#">Posts</a> <ul class="dl-submenu"> <li><a href="http://localhost:4000/posts/">All Posts</a></li> <li><a href="http://localhost:4000/tags/">All Tags</a></li> </ul> </li> <li><a href="http://localhost:4000/projects/" >Projects</a></li> </ul><!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title feature "> <h1>TextCNN on UGC (user generated content) moderation</h1> <h4>18 Jul 2018</h4> <p class="reading-time"> <i class="fa fa-clock-o"></i> Reading time ~4 minutes </p><!-- /.entry-reading-time --> <a class="btn zoombtn" href="http://localhost:4000/projects/"> <i class="fa fa-chevron-left"></i> </a> </div> <h2 id="intro">Intro</h2> <p>TextCNN is a good case demonstrating how neural-network could not only learn from the data, but also do the feature extraction for us.</p> <p>In Indeed we got bunch of text data from our user, like resume, job-description, company related content like reviews and Q&amp;A. These user-generated-content is our most valuable asset. To help people get good jobs we’re constantly trying better way to learn more from these text data.</p> <p>Here’s the slide:</p> <center> <iframe src="//www.slideshare.net/slideshow/embed_code/key/w89wo7k3FIzo8C" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/marsanmars/text-cnn-on-acme-ugc-moderation" title="Text cnn on acme ugc moderation" target="_blank">Text cnn on acme ugc moderation</a> </strong> from <strong><a href="//www.slideshare.net/marsanmars" target="_blank">Marsan Ma</a></strong> </div> </center> <h2 id="the-concept-of-textcnn">The concept of TextCNN</h2> <ol> <li>taking the concatenated word embeddings of a sentence or article as pixels</li> <li>use filters to learn extracting features out of them</li> <li>then use a max-pooling layer to aggregate all the features</li> <li>Finally, learn from those features by the final fully-connected layers.</li> </ol> <h2 id="if-you-prefer-it-explained-in-code">If you prefer it explained in code</h2> <p><img src="/assets/img/blog/textcnn_code.png" alt="TextCNN Code" /></p> <p>Let’s say we limit our input paragraph length as 140 words.</p> <p>For the parameters of embedding layer, 60k is the number of top words I usually use for learning English, which means we’re using a English dictionary only contains 60k most frequently used words. But I think it’s more like a upper-bound, you could really start with 10k or 30k should be fine.</p> <p>The embedding dimension is 300 because I use the pre-trained embedding “FastText” trained from wiki data by Facebook in 2017. Again it’s also a pretty large one, you could find GloVe which is in 128 dimension. I prefer FastText just because I like new stuff, and the idea behind it is fancy.</p> <p>If you wanna try your own embedding, there is a <a href="https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html">rule-of-thumb in a 2017 Google Blog</a> saying It’s better be the 4th root of your dictionary size. I have no luck on training it myself and beat using pre-trained one, so I don’t know whether it’s a good rule. But people say you could try from 64 to 1024.</p> <p>Then for the filters, we got 3 different stride size: [2, 3, 4]. So for each of them we have corresponding 1d-convolution layer with 2 filters, and the MaxPool layer is just taking maximum value from convolution result.</p> <p>Finally all the output of MaxPool layer will be concatenated into a vector, learn by the final multi-layer-perceptron.</p> <p>The dropout probability being 0.5 because Hinton said so. Usually it likely being the best or close to. (Except those very aggressive dropout like input dropout or embedding dropout.)</p> <h2 id="next-steps">Next steps</h2> <p>Now you know TextCNN, but one of the merit of neural network architecture is, you could easily combine different models and make them trained together.</p> <p>For example if you feel the jobTitle out of resume is something worth emphasizing on, you could make a dedicated TextCNN model and concatenate the vector before the final multi-layer-perceptron, and then learn from this large vector like they’re all extracted features from different models.</p> <p><img src="/assets/img/blog/textcnn_ex1.png" alt="TextCNN Code" /></p> <p>Also, if you feel you’re so good at feature engineering and pretty sure you have some feature that model just can’t be better than you. You could also concatenate your manual crafted features into this big feature vector, make them learned together.</p> <p><img src="/assets/img/blog/textcnn_ex2.png" alt="TextCNN Code" /></p> <h2 id="why-you-should-try-it">Why you should try it</h2> <p>First, we’re expecting it brings good performance, since mostly n-gram usually would be the main feature for learning from text, and TextCNN is doing a much better job than n-gram.</p> <p>It’s using embedding so the resolution is much better than word level, and it works not just the exact same words, but also for similar meaning words. And it’s training these feature-learning process, including the embedding and convolution filters during the supervised-learning process to make them specifically fit your data, your purpose.</p> <p>Also since we’re not doing feature extraction by ourself, we don’t need to explicitly doing them while deploying. Thus we save both the develop time and the computing cost of feature extracting. Besides many fancy features, for examples like features comes from unsupervised learning methods like LDA, NMF, or some indirect usage of embeddings.</p> <p>Finally you could steal from the giants by using the pretrained embeddings like word2vec, Glove or FastText. It could give you a boost, and especially helpful if you just don’t really got at least millions of samples to learn the embedding all by yourself.</p> <p>Also, there are some merits natively comes from it just because it’s neural network model.</p> <p>Previously if we want to train an ensemble model, you have to use some indirect ways like saving all the cross-validation results and make them as input of the 2nd pipeline model to train on their outputs.</p> <p>In neural network you could ensemble whatever layers you like into one graph, and just train them together from the very beginning. Like, if you just can’t decide you want use RNN or CNN, you could encode your text data by both of them and concatenate them together!</p> <h2 id="deployment-in-java">Deployment in Java</h2> <p>The keras model, while backed by tensorflow, could be dumped as tensorflow graph and imported in Java. So you don’t need to deploy it as a service in python, then called by Java and worry about handling the exceptions of communication or service accessibility or reliability.</p> <p>And the Java code is super easy, like this:</p> <p><img src="/assets/img/blog/textcnn_ex3.png" alt="TextCNN Deploy" /></p> <p>1st you import the model in one line. 2nd you give it the input, which is the tokenized text. 3rd you get the predicted results, and this prediction could be called in batch.</p> <p>That’s all. Everything is maintained in-process, no feature engineering, no http or boxcar request.</p> <div class="entry-meta"> <br> <hr> <span class="entry-tags"><a href="http://localhost:4000/tags/#nlp" title="Pages tagged nlp" class="tag"><span class="term">nlp</span></a><a href="http://localhost:4000/tags/#deep learning" title="Pages tagged deep learning" class="tag"><span class="term">deep learning</span></a><a href="http://localhost:4000/tags/#neural network" title="Pages tagged neural network" class="tag"><span class="term">neural network</span></a><a href="http://localhost:4000/tags/#cnn" title="Pages tagged cnn" class="tag"><span class="term">cnn</span></a></span> <span class="social-share"> <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/text-cnn-on-ugc-moderation/" title="Share on Facebook" class="tag"> <span class="term"><i class="fa fa-facebook-square"></i> Like</span> </a> <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/text-cnn-on-ugc-moderation/" title="Share on Twitter" class="tag"> <span class="term"><i class="fa fa-twitter-square"></i> Tweet</span> </a> <a href="https://plus.google.com/share?url=http://localhost:4000/text-cnn-on-ugc-moderation/" title="Share on Google+" class="tag"> <span class="term"><i class="fa fa-google-plus-square"></i> +1</span> </a> </span> <div style="clear:both"></div> </div> </div> </div> <section id="disqus_thread" class="animated fadeInUp"></section><!-- /#disqus_thread --> </header> <!-- JS --> <script src="http://localhost:4000/assets/js/jquery-1.12.0.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.dlmenu.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.goup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.magnific-popup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.fitvid.min.js"></script> <script src="http://localhost:4000/assets/js/scripts.js"></script> <script src="http://localhost:4000/assets/js/site.js"></script> <!-- Asynchronous Google Analytics snippet --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-32764178-10', 'auto'); ga('require', 'linkid', 'linkid.js'); ga('send', 'pageview'); </script> <script type="text/javascript"> var disqus_shortname = 'marsan-ma'; (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> <!-- MathJax --> <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </body> </html>
