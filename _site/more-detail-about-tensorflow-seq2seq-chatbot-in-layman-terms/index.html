<!DOCTYPE html> <!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]--> <!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]--> <!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]--> <!--[if gt IE 8]><!--> <html class="no-js"><!--<![endif]--> <head> <meta charset="UTF-8"> <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> <meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"> <title>Detailed explaination of the features and implementations about the chatbot in layman's terms &#8211; Marsan Ma's info</title> <meta name="description" content="Marsan Ma's info"> <meta name="keywords" content="chatbot, deep learning, neural network, rnn"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:image" content="https://4.bp.blogspot.com/-aArS0l1pjHQ/Vjj71pKAaEI/AAAAAAAAAxE/Nvy1FSbD_Vs/s640/2TFstaticgraphic_alt-01.png"> <meta name="twitter:title" content="Detailed explaination of the features and implementations about the chatbot in layman's terms"> <meta name="twitter:description" content="Here I will try to explain some algorithm and implementation details about the work “the tensroflow chatbot” in layman’s terms. Like dictionary space compression/projection, anti-language model, reinforcement learning… etc."> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="Detailed explaination of the features and implementations about the chatbot in layman's terms"> <meta property="og:description" content="Here I will try to explain some algorithm and implementation details about the work “the tensroflow chatbot” in layman’s terms. Like dictionary space compression/projection, anti-language model, reinforcement learning… etc."> <meta property="og:url" content="http://localhost:4000/more-detail-about-tensorflow-seq2seq-chatbot-in-layman-terms/"> <meta property="og:site_name" content="Marsan Ma's info"> <meta property="og:image" content="http://localhost:4000/assets/img/logo.png"> <link rel="canonical" href="http://localhost:4000/more-detail-about-tensorflow-seq2seq-chatbot-in-layman-terms/"> <link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Marsan Ma's info Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css"> <!-- JS --> <script src="http://localhost:4000/assets/js/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" href="http://localhost:4000/assets/img/favicons/apple-icon-precomposed.png"> <link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="http://localhost:4000/favicon.png" /> <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" /> <!-- Background Image --> <style type="text/css">body {background-image:url(http://localhost:4000/assets/img/placeholder-big.jpg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> <style type="text/css">.feature {background-image:url(https://4.bp.blogspot.com/-aArS0l1pjHQ/Vjj71pKAaEI/AAAAAAAAAxE/Nvy1FSbD_Vs/s640/2TFstaticgraphic_alt-01.png);}</style> </head> <body> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="http://localhost:4000/">Home</a></li> <li> <a href="#">About</a> <ul class="dl-submenu"> <li> <img src="http://localhost:4000/assets/img/logo.png" alt="Marsan Ma's info photo" class="author-photo"> <h4>Marsan Ma's info</h4> <p>Marsan Ma's info</p> </li> <li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="http://facebook.com/marsan.mars" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-facebook-square"></i> Facebook</a> </li> <li> <a href="http://linkedin.com/in/marsanma" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a> </li> <li> <a href="http://github.com/Marsan-Ma" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> <li> <a href="mailto:marsan@gmail.com" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-envelope-square"></i> Email</a> </li> </ul><!-- /.dl-submenu --> </li> <li> <a href="#">Posts</a> <ul class="dl-submenu"> <li><a href="http://localhost:4000/posts/">All Posts</a></li> <li><a href="http://localhost:4000/tags/">All Tags</a></li> </ul> </li> <li><a href="http://localhost:4000/projects/" >Projects</a></li> </ul><!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title feature "> <h1>Detailed explaination of the features and implementations about the chatbot in layman's terms</h1> <h4>12 Oct 2016</h4> <p class="reading-time"> <i class="fa fa-clock-o"></i> Reading time ~5 minutes </p><!-- /.entry-reading-time --> <a class="btn zoombtn" href="http://localhost:4000/projects/"> <i class="fa fa-chevron-left"></i> </a> </div> <h1 id="tensorflow-chatbot">tensorflow chatbot</h1> <h3 id="with-seq2seq--attention--dict-compress--beam-search--anti-lm--deep-reinforcement-learning--facebook-messenger-server">(with seq2seq + attention + dict-compress + beam search + anti-LM + deep reinforcement learning + facebook messenger server)</h3> <p>Github Repository: <a href="https://github.com/Marsan-Ma/tf_chatbot_seq2seq_antilm">https://github.com/Marsan-Ma/tf_chatbot_seq2seq_antilm</a></p> <p>Here I’ll try to explain some algorithm and implementation details about <a href="https://github.com/Marsan-Ma/tf_chatbot_seq2seq_antilm">this work</a> in layman’s terms.</p> <h2 id="sequence-to-sequence-model">Sequence to sequence model</h2> <h3 id="what-is-a-language-model">What is a language model?</h3> <p>Let’s say a language model is … <br /> a) Trained by a lot of corpus.<br /> b) It could predict the <strong>probability of next word</strong> given foregoing words.<br /> =&gt; It’s just conditional probability, <strong>P(next_word | foregoing_words)</strong><br /> c) Since we could predict next word: <br /> =&gt; then predict even next, according to words just been generated<br /> =&gt; continuously, we could produce sentences, even paragraph.</p> <p>We could easily achieve this by simple <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs">LSTM model</a>.</p> <h3 id="the-seq2seq-model-architecture">The seq2seq model architecture</h3> <p>Again we quote this seq2seq architecture from [Google’s blogpost] <a href="http://googleresearch.blogspot.ru/2015/11/computer-respond-to-this-email.html"><img src="http://4.bp.blogspot.com/-aArS0l1pjHQ/Vjj71pKAaEI/AAAAAAAAAxE/Nvy1FSbD_Vs/s640/2TFstaticgraphic_alt-01.png" alt="seq2seq" /></a></p> <p>It’s composed of two language model: encoder and decoder. Both of them could be LSTM model we just mentioned.</p> <p>The encoder part accept input tokens and transform the whole input sentence into an embedding <strong>“thought vector”</strong>, which express the meaning of input sentence in our language model domain.</p> <p>Then the decoder is just a language model, like we just said, a language model could generate new sentence according to foregoing corpus. Here we use this <strong>“thought vector”</strong> as kick-off and receive the corresponding mapping, and decode it into the response.</p> <h3 id="reversed-encoder-input-and-attention-mechanism">Reversed encoder input and Attention mechanism</h3> <p>Now you might wonder:<br /> a) Considering this architecture, wil the “thought vector” be dominated by later stages of encoder?<br /> b) Is that enough to represent the meaning of whole input sentence into just a vector?</p> <p>For (a) actually, one of the implement detail we didn’t mention before: the input sentence will be reversed before input to the encoder. Thus we shorten the distance between head of input sentence and head of response sentence. Empirically, it achieves better results. (This trick is not shown in the architecture figure above, for easy to understanding)</p> <p>For (b), another methods to disclose more information to decoder is the <a href="http://arxiv.org/abs/1412.7449">attention mechanism</a>. The idea is simple: allowing each stage in decoder to peep any encoder stages, if they found useful in training phase. So decoder could understand the input sentence more and automagically peep suitable positions while generating response.</p> <h2 id="techniques-about-language-model">Techniques about language model</h2> <h3 id="dictionary-space-compressing-and-projection">Dictionary space compressing and projection</h3> <p>A naive implementation of language model is: suppose we are training english language model, which a dictionary size of 80,000 is roughly enough. As we one-hot coding each word in our dictionary, our LSTM cell should have 80,000 outputs and we will do the softmax to choose for words with best probability…</p> <p>… even if you have lots of computing resource, you don’t need to waste like that. Especially if you are dealing with some other languages with more words like Chinese, which 200,000 words is barely enough.</p> <p>Practically, we could reduce this 80,000 one-hot coding dictionary into embedding spaces, we could use like 64, 128 or 256 dimention to embed our 80,000 words dictionary, and train our model with only by this lower dimention. Then finally when we are generating the response, we project the embedding back into one-hot coding space for dictionary lookup.</p> <h3 id="beam-search">Beam search</h3> <p>The original implementation of tensorflow decode response sentence greedily. Empirically this trapped result in local optimum, and result in dump response which do have maximum probability in first couple of words.</p> <p>So we do the beam search, keep best N candidates and move-forward, thus we could avoid local optimum and find more longer, interesting responses more closer to global optimum result.</p> <p>In <a href="http://arxiv.org/abs/1412.7449">this paper</a>, Google Brain team found that beam search didn’t benefit a lot in machine translation, I guess that’s why they didn’t implement beam search. But in my experience, chatbot do benefit a lot from beam search.</p> <h2 id="anti-language-model">Anti-Language Model</h2> <h3 id="generic-response-problem">Generic response problem</h3> <p>As the seq2seq model is trained by <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">MLE</a> (maximum likelyhood estimation), the model do follow this object function by finding the “most possible” response well. But in human dialogue, a response with high probability like “thank you”, “I don’t know”, “I love you” is not informative at all.</p> <p>As currently we haven’t find a good enough object function to replace MLE, there are some works to suppress this “generic response problem”.</p> <h3 id="supressing-generic-response">Supressing generic response</h3> <p>The work of <a href="https://arxiv.org/abs/1606.01541">Li. et al</a> from Stanford and Microsoft Research try to suppress generic response by lower the probability of generic response from candidates while doing the beam search.</p> <p>The idea is somewhat like Tf-Idf: if this response is suitable for all kinds of foregoing sentence, which means it’s not specific answer for current sentence, then we discard it.</p> <p>According my own experiment result, this helps a lot! Although the cost is that we will choose something grammatically not so correct, but most of time the effect is acceptable. It does generate more interesting, informative response.</p> <h2 id="deep-reinforcement-learning">Deep Reinforcement Learning</h2> <h3 id="reinforcement-learning">Reinforcement learning</h3> <p>Reinforcement learning is a promising domain now (in 2016). It’s promising because it solve the delayed reward problem, and that’s a huge merit for chatbot training. Since we could judge a continuous dialogue includeing several sentences, rather than one single sentence at a time. We could design more sophiscated metrics to reward the model and make it learn more abstract ideas.</p> <h3 id="implement-tricks-in-tensorflow">Implement tricks in tensorflow</h3> <p>The magic of tensorflow is that it construct a graph, which all the computing in graph could be dispatched automagically to CPU, GPU, or even distributed system (more CPU/GPU).</p> <p>So far tensorflow have no native supporting operations for the delayed rewarding, so we have to do some work-around. We will calculate the gradients in graph, and accumulate and do post-processing to them out-of-graph, finally inject them back to do the <code class="highlighter-rouge">apply_gradient()</code>. You could find a minimum example in <a href="https://github.com/awjuliani/DeepRL-Agents/blob/master/Policy-Network.ipynb">this ipython notebook</a>.</p> <div class="entry-meta"> <br> <hr> <span class="entry-tags"><a href="http://localhost:4000/tags/#chatbot" title="Pages tagged chatbot" class="tag"><span class="term">chatbot</span></a><a href="http://localhost:4000/tags/#deep learning" title="Pages tagged deep learning" class="tag"><span class="term">deep learning</span></a><a href="http://localhost:4000/tags/#neural network" title="Pages tagged neural network" class="tag"><span class="term">neural network</span></a><a href="http://localhost:4000/tags/#rnn" title="Pages tagged rnn" class="tag"><span class="term">rnn</span></a></span> <span class="social-share"> <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/more-detail-about-tensorflow-seq2seq-chatbot-in-layman-terms/" title="Share on Facebook" class="tag"> <span class="term"><i class="fa fa-facebook-square"></i> Like</span> </a> <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/more-detail-about-tensorflow-seq2seq-chatbot-in-layman-terms/" title="Share on Twitter" class="tag"> <span class="term"><i class="fa fa-twitter-square"></i> Tweet</span> </a> <a href="https://plus.google.com/share?url=http://localhost:4000/more-detail-about-tensorflow-seq2seq-chatbot-in-layman-terms/" title="Share on Google+" class="tag"> <span class="term"><i class="fa fa-google-plus-square"></i> +1</span> </a> </span> <div style="clear:both"></div> </div> </div> </div> <section id="disqus_thread" class="animated fadeInUp"></section><!-- /#disqus_thread --> </header> <!-- JS --> <script src="http://localhost:4000/assets/js/jquery-1.12.0.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.dlmenu.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.goup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.magnific-popup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.fitvid.min.js"></script> <script src="http://localhost:4000/assets/js/scripts.js"></script> <script src="http://localhost:4000/assets/js/site.js"></script> <!-- Asynchronous Google Analytics snippet --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-32764178-10', 'auto'); ga('require', 'linkid', 'linkid.js'); ga('send', 'pageview'); </script> <script type="text/javascript"> var disqus_shortname = 'marsan-ma'; (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> <!-- MathJax --> <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </body> </html>
